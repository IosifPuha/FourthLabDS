{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# METODI PREDITTIVI\n",
    "\n",
    "\n",
    "09/04/2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8RBBmMNQhql2"
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G1R7cBbvzpt9"
   },
   "source": [
    "# Parte 1. Regressione Lineare "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DM8a4SdImrHm"
   },
   "source": [
    "Utilizziamo la tabella integrate_titles che abbiamo prodotto durante il primo laboratorio. Vi ricordo che abbiamo effettuato integrazione di due dataset provenienti da Disney+ e Netflix, contenenti informazioni circa film e serie tv rilasciate sulle due piattaforme di streaming. Il dataset integrato è stato pulito e risulta quindi pronto per ulteriori analisi.\n",
    "\n",
    "Importiamo il dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PnExuBeH_YAz"
   },
   "outputs": [],
   "source": [
    "#codice qui "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xTJyzFFimxXp"
   },
   "source": [
    "visualizziamo il dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y6tAnKq5mxn0"
   },
   "outputs": [],
   "source": [
    "#codice qui per vedere numero di elementi e informazioni sulle colonne, eliminare eventuali elementi nulli "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3annwavjm6p6"
   },
   "source": [
    "Supponiamo di voler stimare una funzione che preveda l'imdb_score a partire dallo score tmdb. Prima di tutto, possiamo utilizzare una rappresentazione grafica per verificare se le due features siano correlate, e se sia quindi possibile utilizzare una di queste features per predire l'altra. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ftv9Xxn5nMhV"
   },
   "outputs": [],
   "source": [
    "#codice qui \n",
    "plt.title('scores')\n",
    "plt.xlabel('tmdb_score')\n",
    "plt.ylabel('imdb_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xmZDpNCwnpow"
   },
   "source": [
    "verifichiamo la correlazione utilizzando il coefficiente di correlazione di Pearson (r). \n",
    "\n",
    "Vi ricordo che r ha valori nell'intervallo [-1,1].  \n",
    "\n",
    "Inoltre:\n",
    "\n",
    "r in [0,0.3] debole correlazione;\n",
    "\n",
    "r in [0.3,0.7] moderata correlazione;\n",
    "\n",
    "r in [0.7,1] forte correlazione; \n",
    "\n",
    "i valori negativi del coefficiente di correlazione indicano una correlazione inversa, cioè all'aumentare di una caratteristica diminuisce l'altra e viceversa. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hc7G46ZzoHkP"
   },
   "outputs": [],
   "source": [
    "#codice qui "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VrySKCy7oWFD"
   },
   "source": [
    "plottiamo in falsi colori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qod0pJyUoXxH"
   },
   "outputs": [],
   "source": [
    "#codice qui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iokaYFoinMEK"
   },
   "source": [
    "Ora ci chiediamo, quale modello di machine learning possiamo utilizzare per stimare una funzione che preveda l'imdb_score a partire dallo score tmdb. \n",
    "\n",
    "Dobbiamo determinare una relazione tra predittori e una variabile di risposta (che possiamo considerare continua).\n",
    "\n",
    "Possiamo quindi utilizzare un modello di Regressione lineare.\n",
    "\n",
    "Ricordate che dobbiamo dividere il dataset a disposizione in due diversi gruppi:\n",
    "\n",
    "* Training Set -> porzione di dati che utilizziamo per il training del nostro modello di regressione lineare;\n",
    "\n",
    "* Validation Set -> porzione di dati che utilizziamo per valutare il nostro modello precedentemente allenato.\n",
    "\n",
    "Non esiste un unico modo per dividere il dataset in training e validation, normalmente, si utilizza un random split con una certa percentuale (per esempio 70/30 per training/test).\n",
    "\n",
    "\n",
    "Usiamo la libreria scikit-learn, lo schema che dovrete usare e' il seguente:\n",
    "\n",
    "1. Definire le caratteristiche da usare;\n",
    "2. Definire X e y; \n",
    "3. Dividere il dataset in training e validation; \n",
    "4. Istanziare un oggetto della classe LinearRegression;\n",
    "5. Allenare usando la funzione fit invocata sull'oggetto istanziato (passando il training set!);\n",
    "6. Visualizzare i coefficienti imparati: useremo gli attributi *intercept_=* e *coef_* sull'oggetto ottenuto come output della funzione fit.\n",
    "\n",
    "In scikit-learn esiste la funzione:\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y)\n",
    "\n",
    "che effettua per noi lo splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8A5M06qWp7gK"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#codice qui "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DDO-IYAAp-D-"
   },
   "source": [
    "adesso implementiamo la regressione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iGFPhrJzp9jD"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "regressor = LinearRegression()\n",
    "\n",
    "#codice qui "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BMHzoNKsryYU"
   },
   "source": [
    "Adesso possiamo usare il modello imparato, per effettuare predizioni sul validation set. E' sufficiente usare la funzione predict sull'oggetto restituito da fit, passando come argomento x_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eJJ_Z7xSrzfj"
   },
   "outputs": [],
   "source": [
    "#codice qui \n",
    "\n",
    "plt.scatter(X_valid,y_hat)\n",
    "plt.scatter(X_valid,y_valid,c='r',alpha=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WY0lMQqsr7Vv"
   },
   "source": [
    "Ora, come possiamo stimare la precisione della funzione che abbiamo imparato?\n",
    "\n",
    "Sappiamo che non esiste una soluzione perfetta, ma possiamo trovare la soluzione migliore possibile, con i dati a disposizione. Per trovarla, useremo stime degli errori.\n",
    "\n",
    "Abbiamo visto che ci sono tre metriche per valutare i modelli a regressione di machine learning:\n",
    "\n",
    "lo scarto medio assoluto (MAE - Mean Absolute Error);\n",
    "l’errore quadratico medio (MSE - Mean Squared Error);\n",
    "la radice dell’errore quadratico medio (RMSE - Root of Mean Squared Error).\n",
    "ESERCIZIO: scrivete una funzione che implementi ciascuna delle tre metriche sopra descritte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BgqWVd1jsBCJ"
   },
   "outputs": [],
   "source": [
    "def MSE (y_pred,y_true):\n",
    "\n",
    "  #codice qui \n",
    "\n",
    "def MAE (y_pred,y_true):\n",
    "\n",
    "  #codice qui \n",
    "\n",
    "\n",
    "def RMSE (y_pred,y_true):\n",
    "\n",
    " #codice qui "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3B82RzOjsJvg"
   },
   "source": [
    "usate le tre funzioni appena definite, per calcolare le tre metriche sul modello di regressione lineare appena ottenuto (sul validation set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jlpx-AETsJ2z"
   },
   "outputs": [],
   "source": [
    "#MAE\n",
    "\n",
    "\n",
    "\n",
    "#MSE\n",
    "\n",
    "\n",
    "#RMSE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8yiBg4ocsW7B"
   },
   "source": [
    "possiamo anche utilizzare le funzioni messe a disposizione da scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ia_3zZSgsWcM"
   },
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics \n",
    "print ('MAE:', metrics.mean_absolute_error(y_valid, y_pred))\n",
    "print ('MSE:', metrics.mean_squared_error(y_valid, y_pred))\n",
    "print ('RMSE:', np.sqrt(metrics.mean_squared_error(y_valid, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kr08jFpjslhP"
   },
   "source": [
    "Come faccio a sapere se questo risultato e' un buon risultato oppure no?\n",
    "\n",
    "Determiniamo il modello nullo.\n",
    "\n",
    "il modello nullo rappresenta in modo efficace il fatto di tirare a indovinare più e più volte il risultato atteso, e vedere l’efficacia del modello.\n",
    "\n",
    "Nella regressione, possiamo sostituire tutti i valori della feature imdb_score con la media sull'intero dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EGmXwSkAsl7t"
   },
   "outputs": [],
   "source": [
    "#calcolate lo score medio\n",
    "\n",
    "\n",
    "# create la nuova x con lo stesso numero di campioni del validation set originale, e con tutti i valori uguali al valore medio dello score appena calcolato\n",
    "null_model_y = [mean_imdb_score] * y_valid.shape[0]\n",
    "\n",
    "\n",
    "#stampate gli errori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_zwOwuF2tTxp"
   },
   "source": [
    "ESERCIZIO.\n",
    "\n",
    "* Adesso, utilizzate come test set la tabella amazon_titles. \n",
    "\n",
    "1. Pulite e preparate il dataset;\n",
    "\n",
    "2. Applicate il modello di regressione imparato;\n",
    "\n",
    "3. Sfruttate errori a dispozione e modello nullo per determinare se riusciamo a generalizzare bene verso questo set di dati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "60Z0_abhtogF"
   },
   "outputs": [],
   "source": [
    "#leggiamo e visualizziamo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CzP_EDmqtyB7"
   },
   "outputs": [],
   "source": [
    "#verifichiamo elementi nulli ed eliminamo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ey2wD5GNt67-"
   },
   "outputs": [],
   "source": [
    "#applichiamo il modello imparato\n",
    "\n",
    "#visualizziamo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uAio9TnEvL-E"
   },
   "source": [
    "calcoliamo gli errori corrispondenti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EFhSjTIPvNrg"
   },
   "outputs": [],
   "source": [
    "#codice qui, usate le funzioni scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Sc_H46Hu-vv"
   },
   "outputs": [],
   "source": [
    "#calcolate lo score medio\n",
    "\n",
    "# create la nuova x con lo stesso numero di campioni del validation set originale, e con tutti i valori uguali al valore medio dello score appena calcolato\n",
    "\n",
    "\n",
    "#calcoliamo errori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Tjm6Ao0vYet"
   },
   "source": [
    "cosa pensate del modello imparato? traete le opportune conclusioni"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uauc51Tt0cAt"
   },
   "source": [
    "# Parte 2. Regressione Logistica "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FTGrgQx2vsOx"
   },
   "source": [
    "Adesso, proviamo a risolvere un problema di classificazione, utilizzando la regressione logistica, come visto a lezione. \n",
    "\n",
    "\n",
    "Riuscite a trasformare il nostro problema di stimare imdb_score a partire dal tmdb_score, da regressione a classificazione? \n",
    "\n",
    "**tip** create una nuova colonna e provate a creare la caratteristica *above_average* che sia:\n",
    "\n",
    "- 1 Se imdb_score > mean(imdb_score);\n",
    "- 0 altrimenti. \n",
    "\n",
    "Usiamo il dataset integrate_titles come fatto in precedenza. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "usJ6ptdAwL4O"
   },
   "outputs": [],
   "source": [
    "#creiamo la colonna integrate_titles['above_average']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SnHwmgxrv6Sk"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GZtfiDj6wCor"
   },
   "source": [
    "Passi da eseguire (molto simile a quanto gia' fatto):\n",
    "\n",
    "1. Splittare dataset in training e test;\n",
    "2. Istanziare un oggetto della classe LogisticRegression;\n",
    "3. Fare fit su training set;\n",
    "4. Usare la funzione score che fornisce l'accuratezza intesa come numero di volte in cui abbiamo predetto correttamente la classe rispetto al totale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XLpLiPFSKivg"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "#codice qui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NGdfF2zXLmMC"
   },
   "source": [
    "Benissimo, siamo riusciti a raggiungere un'accuratezza del 80% con un modello di logistic regression. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Gnli05zwwJu"
   },
   "source": [
    "quale sarebbe un opportuno modello nullo per confrontare?\n",
    "\n",
    "possiamo immaginare di predire sempre la classe più comune. Verificate quale sia, e deducete score per il modello nullo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cSs89P1lw4n9"
   },
   "outputs": [],
   "source": [
    "#codice qui per modello nullo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k0Eu_wxAxDMa"
   },
   "source": [
    "traete le vostre conclusioni."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8GJ8Fpl0LsNs"
   },
   "source": [
    "Compito per casa.\n",
    "\n",
    "Provate ad utilizzare il dataset di amazon come test, e ripetete tutto quanto visto per la tabella integrata di netflix e disney plus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yd5PBZaUxM_v"
   },
   "outputs": [],
   "source": [
    "#applichiamo il modello imparato"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
